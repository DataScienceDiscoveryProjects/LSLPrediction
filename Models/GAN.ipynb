{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "#==============GAN================\n",
        "class Gan():\n",
        "\n",
        "    def __init__(self, data):\n",
        "\n",
        "\n",
        "        self.data = data\n",
        "        self.n_epochs = 10\n",
        "\n",
        "    # Genereta random noise in a latent space\n",
        "    def _noise(self):\n",
        "        noise = np.random.normal(0, 1, self.data.shape)\n",
        "        return noise\n",
        "\n",
        "    def _generator(self):\n",
        "        model = tf.keras.Sequential(name=\"Generator_model\")\n",
        "        model.add(tf.keras.layers.Dense(15, activation='relu',\n",
        "                                        kernel_initializer='he_uniform',\n",
        "                                        input_dim=self.data.shape[1]))\n",
        "        model.add(tf.keras.layers.Dense(30, activation='relu'))\n",
        "        model.add(tf.keras.layers.Dense(\n",
        "            self.data.shape[1], activation='linear'))\n",
        "        return model\n",
        "\n",
        "    def _discriminator(self):\n",
        "        model = tf.keras.Sequential(name=\"Discriminator_model\")\n",
        "        model.add(tf.keras.layers.Dense(25, activation='relu',\n",
        "                                        kernel_initializer='he_uniform',\n",
        "                                        input_dim=self.data.shape[1]))\n",
        "        model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "        # sigmoid => real or fake\n",
        "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "        model.compile(loss='binary_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    # define the combined generator and discriminator model,\n",
        "    # for updating the generator\n",
        "    def _GAN(self, generator, discriminator):\n",
        "        discriminator.trainable = False\n",
        "        generator.trainable = True\n",
        "        model = tf.keras.Sequential(name=\"GAN\")\n",
        "        model.add(generator)\n",
        "        model.add(discriminator)\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "        return model\n",
        "\n",
        "    # train the generator and discriminator\n",
        "    def train(self, generator, discriminator, gan):\n",
        "\n",
        "        # determine half the size of one batch, for updating the  discriminator\n",
        "        # manually enumerate epochs\n",
        "        for epoch in range(self.n_epochs):\n",
        "\n",
        "            # Train the discriminator\n",
        "            generated_data = generator.predict(self._noise())\n",
        "            labels = np.concatenate([np.ones(self.data.shape[0]), np.zeros(self.data.shape[0])])\n",
        "            X = np.concatenate([self.data, generated_data])\n",
        "            discriminator.trainable = True\n",
        "            d_loss , _ = discriminator.train_on_batch(X, labels)\n",
        "\n",
        "            # Train the generator\n",
        "            noise = self._noise()\n",
        "            g_loss = gan.train_on_batch(noise, np.ones(self.data.shape[0]))\n",
        "\n",
        "\n",
        "            print('>%d, d1=%.3f, d2=%.3f' %(epoch+1, d_loss, g_loss))\n",
        "\n",
        "        return generator\n",
        "#==============GAN================"
      ],
      "metadata": {
        "id": "0Az--oi8WAdd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}